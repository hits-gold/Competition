{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model을 통한 수요예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 필요 모듈/패키지 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rc('font', family='malgun gothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "import seaborn as sns\n",
    "import os\n",
    "import missingno as msno\n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "od_raw = pd.read_csv(r\"orders.csv\")\n",
    "display(od_raw.head(), od_raw.info(), od_raw.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od_raw.copy().iloc[:, :]\n",
    "\n",
    "# 열이름 수정\n",
    "od.columns = [\"창고\", \"고객주문번호\", \"CJ주문번호\", \"주문유형\", \"주문날짜\", \"주문시간\", \"고객사코드\", \"주문금액\", \"품목순번\",\n",
    "             \"품목코드\", \"브랜드\", \"품목수량\", \"품목금액\", \"수신여부\", \"주문생성시간\", \"택배구분\", \"상품주문번호\", \"중개업체주문번호\",\n",
    "             \"접수여부\", \"배달예정점소코드\", \"배달예정사원코드\", \"터미널코드\", \"터미널소분류코드\", \"입력자ID\", \"입력일자\",\n",
    "             \"입력시간\", \"권역구분\", \"배송처별주문분할여부\", \"송화인 광역주소\", \"송화인 지역주소\", \"수화인 광역주소\", \"수화인 지역주소\",\n",
    "             \"주문월\", \"주문일\", \"주문요일\", \"주문시\"]\n",
    "\n",
    "# 주문유형에서 정상반출 제거\n",
    "\n",
    "od = od[od[\"주문유형\"] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od.주문날짜 = od.주문날짜.astype(\"datetime64\")\n",
    "od.입력일자 = od.입력일자.astype(\"datetime64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "od.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. feature 추가\n",
    "* 요일별 특성치\n",
    "* 최근 물량 트렌드\n",
    "* 캘린더 적용치 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "# data_raw -> 주문날짜&주문시간대에 따른 전체날짜 데이터\n",
    "\n",
    "od_kx = od[od[\"창고\"] == \"KX007\"] # 곤지암 FC만 포함\n",
    "data_raw = od_kx.groupby([\"주문날짜\", \"주문시\"])[\"품목수량\"].sum().reset_index()  \n",
    "data_raw = data_raw.append(pd.DataFrame(dict(zip(['주문날짜','주문시','품목수량'],\n",
    "                                       [(pd.to_datetime('2021-06-28'),pd.to_datetime('2021-06-28')), \n",
    "                                        (4,5), (0,0)])))).sort_values(by = [\"주문날짜\", \"주문시\"]).reset_index(drop = True)\n",
    "data_raw[\"주문요일\"] = data_raw[\"주문날짜\"].dt.dayofweek                           \n",
    "data_raw[\"주문일\"] = data_raw[\"주문날짜\"].dt.day\n",
    "\n",
    "for i in range(2, 15):\n",
    "    data_raw[f\"주문날짜+{i}\"] = data_raw[\"주문날짜\"].apply(lambda x : x + datetime.timedelta(days = i))\n",
    "\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_raw[data_raw[\"주문날짜\"] >= \"2021-03-22\"].loc[:, \"품목수량\"].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# 최근물량 트렌드 #############################\n",
    "# 7일전, 14일 전을 제외한 최근 2주간 시간\n",
    "data = data_raw[data_raw[\"주문날짜\"] >= \"2021-03-22\"].loc[:, \"주문날짜\" : \"주문일\"].drop(\"품목수량\", axis = 1)\n",
    "for i in range(2, 7):\n",
    "    date_data = data_raw[[f\"주문날짜+{i}\", \"주문시\",\"품목수량\"]].rename(columns = {f\"주문날짜+{i}\" : \"주문날짜\"})\n",
    "    data = pd.merge(data, date_data, on = [\"주문날짜\", \"주문시\"], how = \"left\").rename(columns = {\"품목수량\" : f\"{i}일전 품목수량\"})\n",
    "\n",
    "for i in range(8, 14):\n",
    "    date_data = data_raw[[f\"주문날짜+{i}\", \"주문시\",\"품목수량\"]].rename(columns = {f\"주문날짜+{i}\" : \"주문날짜\"})\n",
    "    data = pd.merge(data, date_data, on = [\"주문날짜\", \"주문시\"], how = \"left\").rename(columns = {\"품목수량\" : f\"{i}일전 품목수량\"})\n",
    "    \n",
    "\n",
    "\n",
    "# 최근 2주동안 동요일 하루평균 수량\n",
    "day_mean_7 = data_raw.groupby(\"주문날짜+7\")[\"품목수량\"].agg([(\"7일전 시간대별 평균수량\",\n",
    "                                              \"mean\")]).reset_index().rename(columns = {\"주문날짜+7\" : \"주문날짜\"})\n",
    "day_mean_14 = data_raw.groupby(\"주문날짜+14\")[\"품목수량\"].agg([(\"14일전 시간대별 평균수량\",\n",
    "                                             \"mean\")]).reset_index().rename(columns = {\"주문날짜+14\" : \"주문날짜\"})\n",
    "\n",
    "data = pd.merge(data, day_mean_7, how = \"left\")\n",
    "data = pd.merge(data, day_mean_14, how = \"left\")\n",
    "\n",
    "############################# 요일별 특성치 #############################\n",
    "\n",
    "#14일 이전의 모든 동요일 동주문시에 대한 수량 평균\n",
    "dd = []\n",
    "for i in range(2424):\n",
    "    df = data_raw[data_raw.주문날짜 < (data.iloc[i, 0] - datetime.timedelta(days = 14))]\n",
    "    df = df[df.주문시 == data.iloc[i].주문시][df.주문요일 == data.iloc[i].주문요일].품목수량.mean()\n",
    "    dd.append(df)\n",
    "data[\"14일 이전 동요일 동주문시 평균수량\"] = dd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################# 캘린더 적용치 #############################\n",
    "\n",
    "# LG생건X네이버 레드위크\n",
    "def red_week(x):\n",
    "    r1 = [pd.to_datetime(f'2021-03-{i}') for i in range(22,29)]\n",
    "    r2 = [pd.to_datetime(f'2021-06-{i}') for i in range(7,16)]\n",
    "    r = r1+r2\n",
    "    if x in r:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data[\"레드위크\"] = data[\"주문날짜\"].map(red_week)    \n",
    "\n",
    "# 네슬레 브랜드데이&구매왕 이벤트\n",
    "def nestle(x):\n",
    "    n = [pd.to_datetime(\"2021-03-22\"), pd.to_datetime(\"2021-04-15\"), \n",
    "         pd.to_datetime(\"2021-05-17\"), pd.to_datetime(\"2021-06-17\")]\n",
    "    if x in n:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "data[\"네슬레\"] = data[\"주문날짜\"].map(nestle)\n",
    "\n",
    "# 뉴트리원 쇼핑라이브 경품 이벤트\n",
    "def nutrione(x):\n",
    "    n = [pd.to_datetime(\"2021-04-25\"), pd.to_datetime(\"2021-04-30\"), \n",
    "         pd.to_datetime(\"2021-05-16\"), pd.to_datetime(\"2021-05-31\"), \n",
    "         pd.to_datetime(\"2021-06-13\"), pd.to_datetime(\"2021-06-27\")]\n",
    "    if x in n:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "data[\"뉴트리원\"] = data[\"주문날짜\"].map(nutrione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"target\"] = target\n",
    "data = data.drop(\"주문날짜\", axis = 1)\n",
    "data.fillna(0, inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. 이상치 경계값으로 치환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier(df, column):\n",
    "    fraud = df[column]\n",
    "    qt_15 = np.percentile(fraud.values, 15)\n",
    "    qt_85 = np.percentile(fraud.values, 85)\n",
    "    \n",
    "    iqr = qt_85 - qt_15\n",
    "    iqr_w = iqr*1.5\n",
    "    lowest_val = qt_15 - iqr_w\n",
    "    highest_val = qt_85 + iqr_w\n",
    "    \n",
    "    low_index = fraud[(fraud < lowest_val)].index\n",
    "    low_qt = qt_15\n",
    "    \n",
    "    high_index = fraud[(fraud >highest_val)].index\n",
    "    high_qt = qt_85\n",
    "    \n",
    "    \n",
    "    return low_index, high_index, low_qt, high_qt\n",
    "\n",
    "# feature\n",
    "for i in data.columns[3:-4]:\n",
    "    low_index, high_index, low_qt, high_qt = get_outlier(data, i)\n",
    "    data.loc[low_index, i] = low_qt\n",
    "    data.loc[high_index, i] = high_qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 12))\n",
    "data.iloc[:, 3:-4].boxplot()\n",
    "plt.xticks(fontsize = 15, rotation = 20)\n",
    "plt.ylim(0, 8500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. feature별 상관관계 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 12))\n",
    "sns.heatmap(data.corr(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from ngboost import NGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1  전통적 방식의 학습 -> 개별 모델 최적화 후 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train -> 3, 4, 5월 데이터\n",
    "## validation  -> 6/1 ~ 6/15\n",
    "## test -> 6/16 ~ 6/30\n",
    "\n",
    "X_train = data.iloc[:1704].drop(\"target\", axis = 1)\n",
    "X_val = data.iloc[1704:2064].drop(\"target\", axis = 1)\n",
    "X_test = data.iloc[2064:].drop(\"target\", axis = 1)\n",
    "\n",
    "y_train = data.iloc[:1704].target\n",
    "y_val = data.iloc[1704:2064].target\n",
    "y_test = data.iloc[2064:].target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 베이지안 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'max_depth':(2, 128),\n",
    "    'n_estimators':(10,500)\n",
    "}\n",
    "\n",
    "def xgb_opt(max_depth, n_estimators):\n",
    "    params = {\n",
    "      'max_depth':int(round(max_depth)),\n",
    "      'n_estimators':int(round(n_estimators))\n",
    "     }\n",
    "    xgb = XGBRegressor(**params, random_state=0, n_jobs=-1)\n",
    "    score = cross_val_score(xgb, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    return -np.sqrt(-np.mean(score))\n",
    "\n",
    "BO_xgb = BayesianOptimization(f=xgb_opt, pbounds=pbounds, random_state=0)\n",
    "BO_xgb.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'max_depth':(2, 128),\n",
    "    'n_estimators':(10,500)\n",
    "}\n",
    "\n",
    "def et_opt(max_depth, n_estimators):\n",
    "    params = {\n",
    "      'max_depth':int(round(max_depth)),\n",
    "      'n_estimators':int(round(n_estimators))\n",
    "   }\n",
    "    et = ExtraTreesRegressor(**params, random_state=0, n_jobs=-1)\n",
    "    score = cross_val_score(et, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    return -np.sqrt(-np.mean(score))\n",
    "\n",
    "BO_et = BayesianOptimization(f=et_opt, pbounds=pbounds, random_state=0)\n",
    "BO_et.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'num_leaves':(2,128),\n",
    "    'max_depth':(2, 128),\n",
    "    'learning_rate':(0.0000001,10),\n",
    "    'n_estimators':(10,500),\n",
    "    'reg_alpha':(0.0000000001, 10),\n",
    "    'reg_lambda':(0.00000000001, 10)\n",
    "}\n",
    "\n",
    "def lgbm_opt(num_leaves, max_depth, learning_rate, n_estimators, reg_alpha, reg_lambda):\n",
    "    params = {\n",
    "      'num_leaves':int(round(num_leaves)),\n",
    "      'max_depth':int(round(max_depth)),\n",
    "      'learning_rate':learning_rate,\n",
    "      'n_estimators':int(round(n_estimators)),\n",
    "      'reg_alpha':reg_alpha,\n",
    "      'reg_lambda':reg_lambda\n",
    "  }\n",
    "    lgbm = LGBMRegressor(**params, random_state=0, n_jobs=-1)\n",
    "    score = cross_val_score(lgbm, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    return -np.sqrt(-np.mean(score))\n",
    "\n",
    "BO_lgbm = BayesianOptimization(f=lgbm_opt, pbounds=pbounds, random_state=0)\n",
    "BO_lgbm.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'max_depth':(2, 128),\n",
    "    'n_estimators':(10,500)\n",
    "}\n",
    "\n",
    "def rf_opt(max_depth, n_estimators):\n",
    "    params = {\n",
    "      'max_depth':int(round(max_depth)),\n",
    "      'n_estimators':int(round(n_estimators))\n",
    "  }\n",
    "    rf = RandomForestRegressor(**params, random_state=0, n_jobs=-1)\n",
    "    score = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    return -np.sqrt(-np.mean(score))\n",
    "\n",
    "BO_rf = BayesianOptimization(f=rf_opt, pbounds=pbounds, random_state=0)\n",
    "BO_rf.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params_xgb = BO_rf.max['params']\n",
    "max_params_xgb['max_depth'] = int(round(max_params_xgb['max_depth']))\n",
    "max_params_xgb['n_estimators'] = int(round(max_params_xgb['n_estimators']))\n",
    "max_params_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params_et = BO_et.max['params']\n",
    "max_params_et['max_depth'] = int(round(max_params_et['max_depth']))\n",
    "max_params_et['n_estimators'] = int(round(max_params_et['n_estimators']))\n",
    "max_params_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params_lgbm = BO_lgbm.max['params']\n",
    "max_params_lgbm['max_depth'] = int(round(max_params_lgbm['max_depth']))\n",
    "max_params_lgbm['n_estimators'] = int(round(max_params_lgbm['n_estimators']))\n",
    "max_params_lgbm['num_leaves'] = int(round(max_params_lgbm['num_leaves']))\n",
    "max_params_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params_rf = BO_rf.max['params']\n",
    "max_params_rf['max_depth'] = int(round(max_params_rf['max_depth']))\n",
    "max_params_rf['n_estimators'] = int(round(max_params_rf['n_estimators']))\n",
    "max_params_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(**max_params_xgb, random_state=0, n_jobs=-1)\n",
    "et = ExtraTreesRegressor(**max_params_et, random_state=0, n_jobs=-1)\n",
    "lgbm = LGBMRegressor(**max_params_lgbm, random_state=0, n_jobs=-1)\n",
    "cat = CatBoostRegressor(random_state=0)\n",
    "rf = RandomForestRegressor(**max_params_rf, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb.fit(X_train, y_train)\n",
    "et.fit(X_train, y_train)\n",
    "lgbm.fit(X_train, y_train)\n",
    "cat.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [xgb, et, lgbm, cat, rf]\n",
    "for model in tqdm(models):\n",
    "    with open(f\"{str(model).split('(')[0].split('.')[0].replace('<','')}.pkl\", 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = pickle.load(open(\"XGBRegressor.pkl\", 'rb'))\n",
    "et = pickle.load(open(\"ExtraTreesRegressor.pkl\", 'rb'))\n",
    "lgbm = pickle.load(open(\"LGBMRegressor.pkl\", 'rb'))\n",
    "cat = pickle.load(open(\"catboost.pkl\", 'rb'))\n",
    "rf = pickle.load(open(\"RandomForestRegressor.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델별 검증/평가데이터 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [xgb, et, lgbm, cat, rf]\n",
    "\n",
    "for model in models:\n",
    "    print(model.__class__.__name__)\n",
    "    print(\"검증데이터 RMSE : \",np.sqrt(mean_squared_error(y_val, model.predict(X_val))))\n",
    "    print(\"평가데이터 RMSE : \",np.sqrt(mean_squared_error(y_test, model.predict(X_test))))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. OOF(Out-of-Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train -> 3, 4, 5월\n",
    "\n",
    "X = data.iloc[:1704].drop(\"target\", axis = 1)\n",
    "X_test = data.iloc[2064:].drop(\"target\", axis = 1)\n",
    "\n",
    "y = data.iloc[:1704].target\n",
    "y_test = data.iloc[2064:].target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "\n",
    "model = xgb\n",
    "xgb_pred = np.zeros((X_test.shape[0]))\n",
    "rmse_list = []\n",
    "for tr_idx, val_idx in kf.split(X, y) :\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model.fit(tr_x, tr_y)\n",
    "    pred = model.predict(val_x)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(val_y, pred))\n",
    "    rmse_list.append(rmse)\n",
    "    \n",
    "    sub_pred = np.array(model.predict(X_test)) / 5\n",
    "    xgb_pred += sub_pred\n",
    "print(f'{model.__class__.__name__}의 5fold 평균 RMSE는 {np.mean(rmse_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = et\n",
    "et_pred = np.zeros((X_test.shape[0]))\n",
    "rmse_list = []\n",
    "for tr_idx, val_idx in kf.split(X, y) :\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model.fit(tr_x, tr_y)\n",
    "    pred = model.predict(val_x)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(val_y, pred))\n",
    "    rmse_list.append(rmse)\n",
    "    \n",
    "    sub_pred = np.array(model.predict(X_test)) / 5\n",
    "    et_pred += sub_pred\n",
    "print(f'{model.__class__.__name__}의 5fold 평균 RMSE는 {np.mean(rmse_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbm\n",
    "lgbm_pred = np.zeros((X_test.shape[0]))\n",
    "rmse_list = []\n",
    "for tr_idx, val_idx in kf.split(X, y) :\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model.fit(tr_x, tr_y)\n",
    "    pred = model.predict(val_x)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(val_y, pred))\n",
    "    rmse_list.append(rmse)\n",
    "    \n",
    "    sub_pred = np.array(model.predict(X_test)) / 5\n",
    "    lgbm_pred += sub_pred\n",
    "print(f'{model.__class__.__name__}의 5fold 평균 RMSE는 {np.mean(rmse_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "\n",
    "model = cat\n",
    "cat_pred = np.zeros((X_test.shape[0]))\n",
    "rmse_list = []\n",
    "for tr_idx, val_idx in kf.split(X, y) :\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model.fit(tr_x, tr_y)\n",
    "    pred = model.predict(val_x)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(val_y, pred))\n",
    "    rmse_list.append(rmse)\n",
    "    \n",
    "    sub_pred = np.array(model.predict(X_test)) / 5\n",
    "    cat_pred += sub_pred\n",
    "print(f'{model.__class__.__name__}의 5fold 평균 RMSE는 {np.mean(rmse_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.Series(cat.feature_importances_, index = X.columns).sort_values(ascending= False)\n",
    "\n",
    "plt.figure(figsize = (20, 12))\n",
    "data.plot.bar()\n",
    "plt.xticks(rotation = 60)\n",
    "plt.title(\"OOF-catboost 모델 피쳐 중요도\")\n",
    "plt.grid()\n",
    "\n",
    "for i, imp in enumerate(data):\n",
    "    plt.text(i, imp+0.1, f\"{np.round(imp, 2)}\", fontsize = 15, ha = \"center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pd.Series(cat.feature_importances_, index = X.columns).sort_values(ascending= False).values:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf\n",
    "rf_pred = np.zeros((X_test.shape[0]))\n",
    "rmse_list = []\n",
    "for tr_idx, val_idx in kf.split(X, y) :\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model.fit(tr_x, tr_y)\n",
    "    pred = model.predict(val_x)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(val_y, pred))\n",
    "    rmse_list.append(rmse)\n",
    "    \n",
    "    sub_pred =np.array(model.predict(X_test)) / 5\n",
    "    rf_pred += sub_pred\n",
    "print(f'{model.__class__.__name__}의 5fold 평균 RMSE는 {np.mean(rmse_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final OOF RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = (xgb_pred + et_pred + lgbm_pred + cat_pred + rf_pred) / 5\n",
    "print(f\"Final blending model RMSE : {np.sqrt(mean_squared_error(y_test, final_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt((mean_squared_error(y_test, cat_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt((mean_squared_error(y_test, lgbm_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt((mean_squared_error(y_test, xgb_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt((mean_squared_error(y_test, et_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt((mean_squared_error(y_test, rf_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_raw[data_raw.주문날짜 > pd.to_datetime(\"2021-06-15\")].주문날짜.astype(\"str\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최고성능 모델 예측값 시각화\n",
    "* OOF CatBoostRegressor  모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test = data.iloc[2064:].target\n",
    "final = pd.DataFrame()\n",
    "final[\"real\"] = y_test\n",
    "final[\"preds\"] = cat_pred\n",
    "final.index = data_raw[data_raw.주문날짜 > pd.to_datetime(\"2021-06-15\")].주문날짜.astype(\"str\").values\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostRegressor모델 예측 시각화\n",
    "rmse = np.sqrt(mean_squared_error(y_test, cat_pred))\n",
    "x = [\"2021-06-01\", \"2021-06-04\", \"2021-06-09\", \"2021-06-13\", \"2021-06-17\", \"2021-06-21\", \"2021-06-25\", \"2021-06-29\"]\n",
    "figure, ax = plt.subplots(figsize = (20, 12))\n",
    "plt.title(\"OOF - CatBoostRegressor\", fontsize = 40)\n",
    "final.preds.plot(c = \"black\", label = \"preds\")\n",
    "final.real.plot(c = \"pink\", label = \"real\")\n",
    "plt.ylabel(\"\")\n",
    "plt.legend(fontsize = 30)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_pred = pd.Series(cat_pred)\n",
    "ml_pred.to_csv(\"results_ml.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
