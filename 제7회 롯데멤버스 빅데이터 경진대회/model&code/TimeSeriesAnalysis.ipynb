{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e96e71",
   "metadata": {},
   "source": [
    "## Feature Generation & Model\n",
    "Lpay의 다음 결제까지 걸릴 시간을 예측한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe5dba",
   "metadata": {},
   "source": [
    "### Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046344c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings ; warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Feature Transformation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Save Model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbcf06",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c00d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../3. 경서경욱_데이터 및 모델 세이브 파일/dataset/\"\n",
    "model_path = \"../3. 경서경욱_데이터 및 모델 세이브 파일/model/\"\n",
    "\n",
    "lpay = pd.read_csv(data_path+'/LPOINT_BIG_COMP_06_LPAY.csv', parse_dates=['de_dt'])\n",
    "lpay['date'] = pd.to_datetime(lpay['de_dt'].astype(str)+' '+lpay['de_hr'].astype(str).str.zfill(2))\n",
    "lpay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569cc8e9",
   "metadata": {},
   "source": [
    "### Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 월, 요일(문자), 주말\n",
    "lpay['DE_M'] = lpay['de_dt'].dt.month\n",
    "lpay[\"consum_day\"] = lpay[\"de_dt\"].dt.dayofweek.map({i:j for i, j in enumerate([\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"])})\n",
    "lpay[\"weekend_whether\"] = lpay[\"consum_day\"].apply(lambda x : 1 if (x == \"Sat\") or (x == \"Sun\") else 0)\n",
    "\n",
    "# 공휴일\n",
    "holiday_list = ['2021-01-01', '2021-02-11', '2021-02-12', '2021-02-13', '2021-03-01',\n",
    "                '2021-05-05', '2021-05-19', '2021-06-06', '2021-08-15', '2021-09-20',\n",
    "                '2021-09-21', '2021-09-22', '2021-10-03', '2021-10-09', '2021-12-25']\n",
    "lpay[\"holiday\"] = lpay[\"de_dt\"].apply(lambda x : 1 if x in holiday_list else 0)\n",
    "lpay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bedd09",
   "metadata": {},
   "source": [
    "### Feature Generation & Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_list = lpay.drop_duplicates(['cust','cop_c','date'])[['cust', 'date']]\\\n",
    "             .groupby('date')['cust'].unique().reset_index()\n",
    "\n",
    "feature = pd.DataFrame()\n",
    "for _, DATE, CUSTS in trade_list.itertuples():\n",
    "    ease = lpay.query('cust in @CUSTS & date <= @DATE')\n",
    "    # 실제 구매액, 구매건수, 평균구매액, 최대구매액\n",
    "    amount = ease.groupby('cust')['buy_am'].agg([('real_pay', np.sum),('consum_count', np.size),\n",
    "                                                 ('mean_pay', lambda x : np.round(np.mean(x))),('max_pay', np.max)])\n",
    "    \n",
    "    # 내점일수, 최근구매일, 구매주기\n",
    "    day = ease.groupby('cust')['de_dt'].agg([('visit_day_count',lambda x: x.nunique()), \n",
    "                                             ('recent_consum_day', lambda x: (ease.de_dt.max() - x.max()).days), \n",
    "                                             ('consum_cycle', lambda x: int((x.max() - x.min()).days / x.nunique()))])\n",
    "    \n",
    "    # 1일 평균구매액, 1일 평균구매건수, 1일 1회 구매\n",
    "    daily = ease.groupby(['cust', 'de_dt'])['buy_am'].agg([('day1_pay', np.sum),('day1_pay_count', np.size)]).reset_index()\\\n",
    "            .groupby('cust').agg({'day1_pay':[('day1_mean_pay', np.mean)],\n",
    "                                  'day1_pay_count':[('day1_mean_pay_count', np.mean),\n",
    "                                                    ('day1_1consum', lambda x: x.tolist().count(1))]}) \n",
    "    daily.columns = daily.columns.get_level_values(1)\n",
    "    \n",
    "    # cop 별 구매비율, 총금액, 평균금액, 구매주기, cop 종류수, 표준편차, \n",
    "    cop = pd.concat([pd.pivot_table(ease, index='cust', columns='cop_c', values='buy_am', aggfunc=np.size, fill_value=0)\\\n",
    "                     .divide(ease.groupby('cust')['cop_c'].size(), axis=0),\n",
    "                     pd.pivot_table(ease, index='cust', columns='cop_c', values='buy_am', aggfunc=np.sum, fill_value=0),\n",
    "                     pd.pivot_table(ease, index='cust', columns='cop_c', values='buy_am', aggfunc=np.mean, fill_value=0),\n",
    "                     pd.pivot_table(ease, index='cust', columns='cop_c', values='de_dt', \n",
    "                                    aggfunc=lambda x: (x.max()-x.min()).days//x.nunique(), fill_value=0),\n",
    "                     ease.groupby(\"cust\")[\"cop_c\"].nunique(),\n",
    "                     pd.pivot_table(ease, index='cust', columns='cop_c', values='buy_am', aggfunc=np.std, fill_value=0)], axis=1)\n",
    "    cop.columns = [f'{j}_{i}' for i in ['ratio','total_amount','mean_amount','consum_cycle'] for j in sorted(ease.cop_c.unique())]\\\n",
    "                  +[\"cop_c_unique\"]\\\n",
    "                  +[f'{i}_sd' for i in cop.columns[ease.cop_c.nunique()*4+1:]]\n",
    "\n",
    "    # 오프라인/온라인 건수, 온라인 비율\n",
    "    onoff = pd.concat([pd.pivot_table(ease, index='cust', columns='chnl_dv', values='buy_am', aggfunc=np.size, fill_value=0)\\\n",
    "                       .rename(columns={1:'off_count', 2:'on_count'}),\n",
    "                       ease.groupby(\"cust\")[\"chnl_dv\"].agg([(\"online_ratio\", np.mean)])], axis=1)\n",
    "\n",
    "    # 월평균구매액,월최대구매액,월최소구매액, 평균방문월, 평균구매월\n",
    "    high = ease.groupby('cust')['buy_am'].agg([('high_rank_pay', lambda x: x.sort_values()[-5:].index.tolist())]) #상위구매액\n",
    "    high = [j for i in high.high_rank_pay for j in i]\n",
    "    month = pd.concat([pd.pivot_table(ease ,index='cust', columns='DE_M', values='buy_am',\n",
    "                                      aggfunc = [np.mean, max, min], fill_value=0),\n",
    "                       ease.groupby('cust')['DE_M'].mean(),\n",
    "                       ease.loc[high].groupby('cust')['DE_M'].mean()], axis=1)\n",
    "    month.columns = [f'{str(j)}_{i}' for i in ['month_mean_pay', 'month_max_pay', 'month_min_pay'] for j in sorted(ease['DE_M'].unique())]\\\n",
    "                    +['mean_visit_month', 'mean_consum_month']\n",
    "\n",
    "    # 요일 종류수, 공휴일 비율, 주말 비율\n",
    "    day_info = pd.concat([ease.groupby(\"cust\")[\"consum_day\"].agg([(\"consum_day_unique\", pd.Series.nunique)]),\n",
    "                          ease.groupby(\"cust\")[\"holiday\"].agg([(\"holiday_ratio\", np.mean)]),\n",
    "                          ease.groupby(\"cust\")[\"weekend_whether\"].agg([(\"weekend_whether_ratio\", np.mean)])], axis=1)\n",
    "    \n",
    "    make_feature = pd.concat([pd.DataFrame({'date':[DATE]*len(CUSTS)}, index=CUSTS),\n",
    "                              amount, day, daily, cop, onoff, month, day_info],axis=1).reset_index()\n",
    "    feature = pd.concat([feature, make_feature])\n",
    "    \n",
    "feature = feature.rename(columns={'index':'cust'}).sort_values(['cust','date']).reset_index(drop=True)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.to_csv(data_path+'/feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f25788",
   "metadata": {},
   "source": [
    "### Generate Target & Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target을 만들고자 하며 마지막 구매의 다음 구매까지 걸리는 시간을 구할 수 없어 임의의 값을 삽입해 처리해 구한다.\n",
    "# 분석 기간 이외의 2040-08-01의 값으로 처리한다.\n",
    "target = pd.concat([feature[['cust','date']],\n",
    "                    pd.DataFrame({'cust':feature.cust.unique(), 'date':['2040-08-01 00:00:00']*feature.cust.nunique()})])\n",
    "target['date'] = pd.to_datetime(target['date'])\n",
    "target = target.sort_values(['cust','date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c27af",
   "metadata": {},
   "outputs": [],
   "source": [
    "target['target'] = target['date'].diff().dt.total_seconds()/60/60\n",
    "\n",
    "# 첫 거래일은 이전 거래부터 현 거래까지의 값을 알 수 없음으로 삭제한다.\n",
    "target = target.iloc[1:].drop(target.query('target < 0').index)\n",
    "\n",
    "# 1년 기간 안의 시간간격 최댓값 24*364보다 크면 임의의 값을 넣은 날의 target값이다.\n",
    "# 즉 고객의 마지막 구매일로 마지막 구매일의 target은 예측하고자 하는 다음 구매시간으로 test data로 구분한다.\n",
    "feature = pd.concat([feature, target.reset_index(drop=True)['target']], axis=1)\n",
    "train = feature.query('target <= 24*364')\n",
    "test = feature.query('target > 24*364') ; del test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1af8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(data_path+'/feature_train.csv', index=False)\n",
    "test.to_csv(data_path+'/feature_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b42f3c",
   "metadata": {},
   "source": [
    "### Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754cefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unuseful columns\n",
    "del train['cust'], train['date']\n",
    "del test['cust'], test['date']\n",
    "\n",
    "# Define data\n",
    "y_train = train['target'] ; del train['target']\n",
    "X_train, X_test = train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputation\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18efb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train.columns] =scaler.fit_transform(X_train) \n",
    "X_test[X_test.columns] = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f36fd0",
   "metadata": {},
   "source": [
    "### Modeling &  Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120cd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations=1000, learning_rate = 0.03, bootstrap_type ='Bayesian', \n",
    "                          devices='0:1', task_type=\"GPU\", random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list =[]\n",
    "for tr_idx, val_idx in kf.split(np.array(X_train)):\n",
    "    tr_x, tr_y = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    model.fit(tr_x, tr_y)\n",
    "    pred = model.predict(val_x)\n",
    "    rmse_list.append(mean_squared_error(val_y, pred)**0.5)\n",
    "    \n",
    "print(f'{model.__class__.__name__}의 10fold 평균 RMSE는 {np.mean(rmse_list)}이다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55248263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일 단위로 변환 \n",
    "print(np.mean(rmse_list)/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, model_path + 'catboost_Lpay.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
