{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BY8IQLZE79oh",
    "outputId": "998b6bb5-9817-4a11-9401-98de07df78fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import missingno as msno\n",
    "import pickle\n",
    "from glob import glob\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "import joblib\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jXfjv5ettIDo"
   },
   "outputs": [],
   "source": [
    "path = (os.path.abspath(\"../input\"))\n",
    "sub_path = (os.path.abspath(\"../submissions\"))\n",
    "\n",
    "sub = pd.read_csv(path + \"/sample_submission.csv\")\n",
    "X_train = pd.read_csv(path + '/X_train_lgbm.csv')\n",
    "X_test = pd.read_csv(path + '/X_test_lgbm.csv')\n",
    "y_train = pd.read_csv(path + '/y_train_lgbm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -> OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "\n",
    "model = LGBMClassifier(random_state = 44)\n",
    "lgbm_pred = np.zeros((X_test.shape[0]))\n",
    "auc_list = []\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "    tr_x, tr_y = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    model.fit(tr_x, tr_y)\n",
    "    pred = model.predict_proba(val_x)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(val_y, pred)\n",
    "    auc_list.append(auc)\n",
    "    \n",
    "    sub_pred = np.array(model.predict_proba(X_test)[:, 1]) / 5\n",
    "    lgbm_pred += sub_pred\n",
    "print(f'{model.__class__.__name__}의 5fold 평균 AUC는 {np.mean(auc_list)}')\n",
    "#1 baseline : 0.8526123651224111\n",
    "#2 baseline + label encoding : 0.8535428309657258\n",
    "#3 baseline + grouping : 0.8408434417734512\n",
    "#4 baseline + binaryohe : 0.8571192393124303\n",
    "#5 baseline + hourmean + title + 주말주중 : 0.8588049959428016 \n",
    "#6 baseline + hourmean + title + weekdaylabelencoding: 0.8596225576452744\n",
    "#6 baseline + hourmean + title + weekdaylabelencoding + cpi_mean + 성실도 + 성실도/status: 0.8605211060959981\n",
    "#7 baseline + hourmean + title + weekdaylabelencoding + cpi_mean : 0.86045 (최고점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"STATUS\"] = lgbm_pred\n",
    "sub.to_csv(sub_path + \"/lgbm_oof.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8ligr5HdZiw"
   },
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(path + '/X_train_dnn.csv')\n",
    "X_test = pd.read_csv(path + '/X_test_dnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRhkIjeaMWmw",
    "outputId": "cde5cd23-321b-4cae-f2c3-a8952df74658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SEEDS RESET\n"
     ]
    }
   ],
   "source": [
    "# 매번 모델링을 할 때마다 동일한 결과를 얻으려면 아래 코드를 실행해야 함.\n",
    "def reset_seeds(reset_graph_with_backend=None):\n",
    "    if reset_graph_with_backend is not None:\n",
    "        K = reset_graph_with_backend\n",
    "        K.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        print(\"KERAS AND TENSORFLOW GRAPHS RESET\")  \n",
    "\n",
    "    np.random.seed(1)\n",
    "    random.seed(2)\n",
    "    tf.compat.v1.set_random_seed(3)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''  # for GPU\n",
    "    print(\"RANDOM SEEDS RESET\") \n",
    "   \n",
    "reset_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gckR6KUpOwPL"
   },
   "outputs": [],
   "source": [
    "# 학습데이터를 Train/Validation 나누고 학습을 진행함.\n",
    "i = int(round(X_train.shape[0] * 0.6,0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1UGaf7ZNZEC",
    "outputId": "bfce1e9a-5768-4210-f99a-0b37f9e4d123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1437/1437 - 5s - loss: 0.5056 - acc: 0.7532 - auc: 0.8063 - val_loss: 0.4859 - val_acc: 0.7539 - val_auc: 0.8316 - 5s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "1437/1437 - 4s - loss: 0.4865 - acc: 0.7541 - auc: 0.8234 - val_loss: 0.4779 - val_acc: 0.7512 - val_auc: 0.8338 - 4s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "1437/1437 - 4s - loss: 0.4855 - acc: 0.7511 - auc: 0.8224 - val_loss: 0.4744 - val_acc: 0.7500 - val_auc: 0.8352 - 4s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "1437/1437 - 4s - loss: 0.4853 - acc: 0.7491 - auc: 0.8217 - val_loss: 0.4725 - val_acc: 0.7502 - val_auc: 0.8359 - 4s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "1437/1437 - 4s - loss: 0.4851 - acc: 0.7478 - auc: 0.8213 - val_loss: 0.4712 - val_acc: 0.7511 - val_auc: 0.8363 - 4s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "1437/1437 - 4s - loss: 0.4850 - acc: 0.7468 - auc: 0.8210 - val_loss: 0.4702 - val_acc: 0.7522 - val_auc: 0.8366 - 4s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "1437/1437 - 4s - loss: 0.4849 - acc: 0.7460 - auc: 0.8208 - val_loss: 0.4693 - val_acc: 0.7533 - val_auc: 0.8368 - 4s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "1437/1437 - 4s - loss: 0.4848 - acc: 0.7453 - auc: 0.8207 - val_loss: 0.4686 - val_acc: 0.7542 - val_auc: 0.8369 - 4s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "1437/1437 - 4s - loss: 0.4848 - acc: 0.7446 - auc: 0.8205 - val_loss: 0.4680 - val_acc: 0.7549 - val_auc: 0.8370 - 4s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "1437/1437 - 4s - loss: 0.4847 - acc: 0.7442 - auc: 0.8204 - val_loss: 0.4674 - val_acc: 0.7556 - val_auc: 0.8371 - 4s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "1437/1437 - 4s - loss: 0.4846 - acc: 0.7440 - auc: 0.8203 - val_loss: 0.4668 - val_acc: 0.7561 - val_auc: 0.8372 - 4s/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "1437/1437 - 4s - loss: 0.4843 - acc: 0.7441 - auc: 0.8205 - val_loss: 0.4663 - val_acc: 0.7566 - val_auc: 0.8373 - 4s/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "1437/1437 - 4s - loss: 0.4841 - acc: 0.7442 - auc: 0.8206 - val_loss: 0.4658 - val_acc: 0.7571 - val_auc: 0.8374 - 4s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "1437/1437 - 4s - loss: 0.4840 - acc: 0.7442 - auc: 0.8206 - val_loss: 0.4654 - val_acc: 0.7574 - val_auc: 0.8374 - 4s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "1437/1437 - 4s - loss: 0.4838 - acc: 0.7442 - auc: 0.8207 - val_loss: 0.4651 - val_acc: 0.7577 - val_auc: 0.8375 - 4s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "1437/1437 - 4s - loss: 0.4837 - acc: 0.7443 - auc: 0.8207 - val_loss: 0.4647 - val_acc: 0.7580 - val_auc: 0.8375 - 4s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "1437/1437 - 4s - loss: 0.4836 - acc: 0.7444 - auc: 0.8208 - val_loss: 0.4644 - val_acc: 0.7583 - val_auc: 0.8376 - 4s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "1437/1437 - 4s - loss: 0.4835 - acc: 0.7445 - auc: 0.8209 - val_loss: 0.4641 - val_acc: 0.7585 - val_auc: 0.8376 - 4s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "1437/1437 - 3s - loss: 0.4833 - acc: 0.7446 - auc: 0.8210 - val_loss: 0.4638 - val_acc: 0.7587 - val_auc: 0.8376 - 3s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "1437/1437 - 3s - loss: 0.4832 - acc: 0.7449 - auc: 0.8211 - val_loss: 0.4636 - val_acc: 0.7589 - val_auc: 0.8377 - 3s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "1437/1437 - 4s - loss: 0.4831 - acc: 0.7450 - auc: 0.8212 - val_loss: 0.4634 - val_acc: 0.7591 - val_auc: 0.8377 - 4s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "1437/1437 - 4s - loss: 0.4830 - acc: 0.7452 - auc: 0.8213 - val_loss: 0.4633 - val_acc: 0.7593 - val_auc: 0.8377 - 4s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "1437/1437 - 4s - loss: 0.4828 - acc: 0.7453 - auc: 0.8214 - val_loss: 0.4631 - val_acc: 0.7594 - val_auc: 0.8377 - 4s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "1437/1437 - 4s - loss: 0.4827 - acc: 0.7454 - auc: 0.8215 - val_loss: 0.4630 - val_acc: 0.7595 - val_auc: 0.8377 - 4s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "1437/1437 - 4s - loss: 0.4826 - acc: 0.7456 - auc: 0.8216 - val_loss: 0.4628 - val_acc: 0.7597 - val_auc: 0.8377 - 4s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "1437/1437 - 4s - loss: 0.4824 - acc: 0.7457 - auc: 0.8218 - val_loss: 0.4627 - val_acc: 0.7598 - val_auc: 0.8378 - 4s/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "1437/1437 - 4s - loss: 0.4823 - acc: 0.7458 - auc: 0.8219 - val_loss: 0.4625 - val_acc: 0.7598 - val_auc: 0.8378 - 4s/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "1437/1437 - 4s - loss: 0.4822 - acc: 0.7460 - auc: 0.8220 - val_loss: 0.4624 - val_acc: 0.7598 - val_auc: 0.8378 - 4s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "1437/1437 - 4s - loss: 0.4821 - acc: 0.7459 - auc: 0.8221 - val_loss: 0.4622 - val_acc: 0.7598 - val_auc: 0.8378 - 4s/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "1437/1437 - 4s - loss: 0.4820 - acc: 0.7461 - auc: 0.8222 - val_loss: 0.4620 - val_acc: 0.7598 - val_auc: 0.8378 - 4s/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "1437/1437 - 4s - loss: 0.4819 - acc: 0.7461 - auc: 0.8223 - val_loss: 0.4618 - val_acc: 0.7599 - val_auc: 0.8378 - 4s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "1437/1437 - 4s - loss: 0.4817 - acc: 0.7463 - auc: 0.8225 - val_loss: 0.4616 - val_acc: 0.7599 - val_auc: 0.8377 - 4s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "1437/1437 - 4s - loss: 0.4816 - acc: 0.7463 - auc: 0.8225 - val_loss: 0.4614 - val_acc: 0.7599 - val_auc: 0.8378 - 4s/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "1437/1437 - 4s - loss: 0.4814 - acc: 0.7465 - auc: 0.8227 - val_loss: 0.4613 - val_acc: 0.7600 - val_auc: 0.8378 - 4s/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "1437/1437 - 4s - loss: 0.4812 - acc: 0.7466 - auc: 0.8229 - val_loss: 0.4613 - val_acc: 0.7600 - val_auc: 0.8378 - 4s/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "1437/1437 - 4s - loss: 0.4810 - acc: 0.7468 - auc: 0.8230 - val_loss: 0.4613 - val_acc: 0.7601 - val_auc: 0.8378 - 4s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "1437/1437 - 3s - loss: 0.4808 - acc: 0.7470 - auc: 0.8232 - val_loss: 0.4612 - val_acc: 0.7601 - val_auc: 0.8378 - 3s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "1437/1437 - 4s - loss: 0.4807 - acc: 0.7471 - auc: 0.8234 - val_loss: 0.4612 - val_acc: 0.7602 - val_auc: 0.8378 - 4s/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "1437/1437 - 4s - loss: 0.4805 - acc: 0.7474 - auc: 0.8235 - val_loss: 0.4611 - val_acc: 0.7601 - val_auc: 0.8378 - 4s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "1437/1437 - 4s - loss: 0.4804 - acc: 0.7475 - auc: 0.8236 - val_loss: 0.4610 - val_acc: 0.7601 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "1437/1437 - 4s - loss: 0.4802 - acc: 0.7476 - auc: 0.8238 - val_loss: 0.4609 - val_acc: 0.7601 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "1437/1437 - 4s - loss: 0.4801 - acc: 0.7477 - auc: 0.8239 - val_loss: 0.4608 - val_acc: 0.7601 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "1437/1437 - 4s - loss: 0.4799 - acc: 0.7478 - auc: 0.8240 - val_loss: 0.4607 - val_acc: 0.7602 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "1437/1437 - 4s - loss: 0.4798 - acc: 0.7480 - auc: 0.8241 - val_loss: 0.4607 - val_acc: 0.7602 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "1437/1437 - 4s - loss: 0.4797 - acc: 0.7482 - auc: 0.8242 - val_loss: 0.4607 - val_acc: 0.7602 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "1437/1437 - 4s - loss: 0.4795 - acc: 0.7484 - auc: 0.8243 - val_loss: 0.4607 - val_acc: 0.7602 - val_auc: 0.8380 - 4s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "1437/1437 - 4s - loss: 0.4794 - acc: 0.7483 - auc: 0.8244 - val_loss: 0.4606 - val_acc: 0.7602 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "1437/1437 - 4s - loss: 0.4793 - acc: 0.7485 - auc: 0.8245 - val_loss: 0.4606 - val_acc: 0.7601 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "1437/1437 - 4s - loss: 0.4792 - acc: 0.7485 - auc: 0.8246 - val_loss: 0.4606 - val_acc: 0.7601 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "1437/1437 - 4s - loss: 0.4791 - acc: 0.7488 - auc: 0.8247 - val_loss: 0.4606 - val_acc: 0.7601 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "1437/1437 - 4s - loss: 0.4791 - acc: 0.7489 - auc: 0.8248 - val_loss: 0.4606 - val_acc: 0.7602 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "1437/1437 - 4s - loss: 0.4790 - acc: 0.7490 - auc: 0.8249 - val_loss: 0.4606 - val_acc: 0.7602 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "1437/1437 - 4s - loss: 0.4789 - acc: 0.7491 - auc: 0.8249 - val_loss: 0.4606 - val_acc: 0.7601 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "1437/1437 - 4s - loss: 0.4788 - acc: 0.7493 - auc: 0.8250 - val_loss: 0.4606 - val_acc: 0.7601 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "1437/1437 - 4s - loss: 0.4787 - acc: 0.7494 - auc: 0.8251 - val_loss: 0.4605 - val_acc: 0.7602 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "1437/1437 - 4s - loss: 0.4786 - acc: 0.7495 - auc: 0.8252 - val_loss: 0.4605 - val_acc: 0.7602 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "1437/1437 - 4s - loss: 0.4786 - acc: 0.7495 - auc: 0.8252 - val_loss: 0.4605 - val_acc: 0.7602 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "1437/1437 - 4s - loss: 0.4785 - acc: 0.7496 - auc: 0.8253 - val_loss: 0.4605 - val_acc: 0.7602 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "1437/1437 - 4s - loss: 0.4784 - acc: 0.7496 - auc: 0.8254 - val_loss: 0.4605 - val_acc: 0.7602 - val_auc: 0.8379 - 4s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "1437/1437 - 4s - loss: 0.4784 - acc: 0.7497 - auc: 0.8254 - val_loss: 0.4605 - val_acc: 0.7603 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "1437/1437 - 4s - loss: 0.4783 - acc: 0.7496 - auc: 0.8255 - val_loss: 0.4604 - val_acc: 0.7603 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "1437/1437 - 4s - loss: 0.4783 - acc: 0.7497 - auc: 0.8256 - val_loss: 0.4604 - val_acc: 0.7604 - val_auc: 0.8379 - 4s/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "1437/1437 - 4s - loss: 0.4782 - acc: 0.7496 - auc: 0.8256 - val_loss: 0.4604 - val_acc: 0.7604 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "1437/1437 - 4s - loss: 0.4782 - acc: 0.7498 - auc: 0.8257 - val_loss: 0.4603 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "1437/1437 - 4s - loss: 0.4781 - acc: 0.7498 - auc: 0.8257 - val_loss: 0.4603 - val_acc: 0.7604 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "1437/1437 - 4s - loss: 0.4781 - acc: 0.7499 - auc: 0.8258 - val_loss: 0.4603 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "1437/1437 - 4s - loss: 0.4780 - acc: 0.7500 - auc: 0.8258 - val_loss: 0.4603 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "1437/1437 - 4s - loss: 0.4780 - acc: 0.7500 - auc: 0.8258 - val_loss: 0.4603 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "1437/1437 - 4s - loss: 0.4779 - acc: 0.7501 - auc: 0.8259 - val_loss: 0.4603 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "1437/1437 - 4s - loss: 0.4779 - acc: 0.7501 - auc: 0.8259 - val_loss: 0.4603 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "1437/1437 - 4s - loss: 0.4778 - acc: 0.7502 - auc: 0.8260 - val_loss: 0.4603 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "1437/1437 - 4s - loss: 0.4778 - acc: 0.7503 - auc: 0.8260 - val_loss: 0.4602 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "1437/1437 - 4s - loss: 0.4778 - acc: 0.7502 - auc: 0.8261 - val_loss: 0.4602 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "1437/1437 - 4s - loss: 0.4777 - acc: 0.7503 - auc: 0.8261 - val_loss: 0.4602 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "1437/1437 - 4s - loss: 0.4777 - acc: 0.7503 - auc: 0.8261 - val_loss: 0.4602 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "1437/1437 - 4s - loss: 0.4777 - acc: 0.7504 - auc: 0.8261 - val_loss: 0.4601 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "1437/1437 - 4s - loss: 0.4776 - acc: 0.7504 - auc: 0.8262 - val_loss: 0.4601 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "1437/1437 - 4s - loss: 0.4776 - acc: 0.7504 - auc: 0.8262 - val_loss: 0.4601 - val_acc: 0.7605 - val_auc: 0.8380 - 4s/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "1437/1437 - 4s - loss: 0.4776 - acc: 0.7505 - auc: 0.8262 - val_loss: 0.4601 - val_acc: 0.7605 - val_auc: 0.8381 - 4s/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "1437/1437 - 4s - loss: 0.4776 - acc: 0.7505 - auc: 0.8263 - val_loss: 0.4600 - val_acc: 0.7605 - val_auc: 0.8381 - 4s/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "1437/1437 - 4s - loss: 0.4775 - acc: 0.7505 - auc: 0.8263 - val_loss: 0.4600 - val_acc: 0.7606 - val_auc: 0.8381 - 4s/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "1437/1437 - 4s - loss: 0.4775 - acc: 0.7506 - auc: 0.8263 - val_loss: 0.4599 - val_acc: 0.7606 - val_auc: 0.8381 - 4s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "1437/1437 - 4s - loss: 0.4775 - acc: 0.7506 - auc: 0.8263 - val_loss: 0.4599 - val_acc: 0.7606 - val_auc: 0.8381 - 4s/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "1437/1437 - 4s - loss: 0.4775 - acc: 0.7507 - auc: 0.8264 - val_loss: 0.4598 - val_acc: 0.7606 - val_auc: 0.8381 - 4s/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "1437/1437 - 4s - loss: 0.4775 - acc: 0.7507 - auc: 0.8264 - val_loss: 0.4598 - val_acc: 0.7605 - val_auc: 0.8381 - 4s/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "1437/1437 - 4s - loss: 0.4774 - acc: 0.7508 - auc: 0.8264 - val_loss: 0.4597 - val_acc: 0.7606 - val_auc: 0.8381 - 4s/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "1437/1437 - 4s - loss: 0.4774 - acc: 0.7508 - auc: 0.8265 - val_loss: 0.4597 - val_acc: 0.7606 - val_auc: 0.8381 - 4s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "1437/1437 - 4s - loss: 0.4774 - acc: 0.7509 - auc: 0.8265 - val_loss: 0.4596 - val_acc: 0.7606 - val_auc: 0.8381 - 4s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "1437/1437 - 4s - loss: 0.4774 - acc: 0.7510 - auc: 0.8265 - val_loss: 0.4595 - val_acc: 0.7606 - val_auc: 0.8381 - 4s/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "1437/1437 - 4s - loss: 0.4773 - acc: 0.7510 - auc: 0.8265 - val_loss: 0.4595 - val_acc: 0.7606 - val_auc: 0.8382 - 4s/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "1437/1437 - 4s - loss: 0.4773 - acc: 0.7511 - auc: 0.8266 - val_loss: 0.4594 - val_acc: 0.7606 - val_auc: 0.8382 - 4s/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "1437/1437 - 4s - loss: 0.4773 - acc: 0.7512 - auc: 0.8266 - val_loss: 0.4593 - val_acc: 0.7605 - val_auc: 0.8382 - 4s/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "1437/1437 - 4s - loss: 0.4772 - acc: 0.7512 - auc: 0.8266 - val_loss: 0.4592 - val_acc: 0.7605 - val_auc: 0.8382 - 4s/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "1437/1437 - 4s - loss: 0.4771 - acc: 0.7513 - auc: 0.8267 - val_loss: 0.4591 - val_acc: 0.7605 - val_auc: 0.8383 - 4s/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "1437/1437 - 4s - loss: 0.4771 - acc: 0.7513 - auc: 0.8268 - val_loss: 0.4590 - val_acc: 0.7604 - val_auc: 0.8383 - 4s/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "1437/1437 - 4s - loss: 0.4770 - acc: 0.7514 - auc: 0.8268 - val_loss: 0.4589 - val_acc: 0.7604 - val_auc: 0.8383 - 4s/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "1437/1437 - 4s - loss: 0.4769 - acc: 0.7515 - auc: 0.8269 - val_loss: 0.4588 - val_acc: 0.7604 - val_auc: 0.8383 - 4s/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "1437/1437 - 4s - loss: 0.4768 - acc: 0.7516 - auc: 0.8270 - val_loss: 0.4588 - val_acc: 0.7605 - val_auc: 0.8383 - 4s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "1437/1437 - 4s - loss: 0.4768 - acc: 0.7516 - auc: 0.8270 - val_loss: 0.4587 - val_acc: 0.7605 - val_auc: 0.8384 - 4s/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "1437/1437 - 4s - loss: 0.4767 - acc: 0.7517 - auc: 0.8271 - val_loss: 0.4586 - val_acc: 0.7606 - val_auc: 0.8384 - 4s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "input = keras.Input(shape=(X_train.shape[1],))\n",
    "with tf.device('/device:GPU:0'):\n",
    "\n",
    "    x = keras.layers.Dense(16, activation='relu')(input)\n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(input, output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', keras.metrics.AUC()])\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),]\n",
    " \n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n",
    "                 batch_size=2048, epochs=100, callbacks=callbacks, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Kzru6nHRd-i"
   },
   "outputs": [],
   "source": [
    "dnn_pred=model.predict(X_test).flatten()\n",
    "sub[\"STATUS\"] = dnn_pred\n",
    "sub.to_csv(sub_path + \"/dnn_submission_12071412.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSENBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = pd.read_csv(sub_path + \"/lgbm_oof.csv\")\n",
    "dnn = pd.read_csv(sub_path + \"/dnn_submission_12071412.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.905859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.064309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.541115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.877863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.069463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355512</th>\n",
       "      <td>1355512</td>\n",
       "      <td>0.260059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355513</th>\n",
       "      <td>1355513</td>\n",
       "      <td>0.143008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355514</th>\n",
       "      <td>1355514</td>\n",
       "      <td>0.151053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355515</th>\n",
       "      <td>1355515</td>\n",
       "      <td>0.223804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355516</th>\n",
       "      <td>1355516</td>\n",
       "      <td>0.047100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1355517 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID    STATUS\n",
       "0              0  0.905859\n",
       "1              1  0.064309\n",
       "2              2  0.541115\n",
       "3              3  0.877863\n",
       "4              4  0.069463\n",
       "...          ...       ...\n",
       "1355512  1355512  0.260059\n",
       "1355513  1355513  0.143008\n",
       "1355514  1355514  0.151053\n",
       "1355515  1355515  0.223804\n",
       "1355516  1355516  0.047100\n",
       "\n",
       "[1355517 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"STATUS\"] = (lgbm.STATUS + dnn.STATUS)/2\n",
    "sub.to_csv(sub_path + \"lgbm_dnn.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DNN_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
